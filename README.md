# Customer-Experience-Analytics

**Week 2 â€“ Task 1: Data Collection and Preprocessing**  
This repository analyzes customer sentiment and user experience for three major Ethiopian mobile banking apps:
- **Commercial Bank of Ethiopia (CBE)**
- **Bank of Abyssinia (BOA)**
- **Dashen Bank**

Task 1 focuses on:

- Scraping Google Play Store reviews  
- Cleaning and preprocessing the data  
- Saving structured datasets for analysis  
- Documenting methodology using GitHub best practices  
---

---

## Task 1 Overview 
Task 1 involves four core components

### 1. Git Setup  
- Created repo with clean structure
- Added .gitignore (ignoring pycache, env files, notebooks checkpoints)
- Added requirements.txt
- Used a dedicated feature branch: task-1
- Committed in small, logical steps

### 2. Web Scraping  
Using `google-play-scraper`, the pipeline collected:
- Review text  
- Rating (1â€“5)  
- Timestamp  
- Bank code  
- App ID
- Source platform  

The scraper gathers 600 reviews per bank (1,800 total), making cross-bank comparisons fair and balanced.

### 3. Preprocessing  
The automated cleaning pipeline performed:

- Duplicate removal  
- Missing value handling  
- Date normalization (`YYYY-MM-DD`)  
- Text cleaning  
- Rating validation  
- Added metadata (`text_length`, `bank_code`)  

### 4. EDA Notebook
The notebook includes:
- Ratings distribution
- Reviews per bank
- Review length distribution
- Interpretation of patterns
- Reproducible code for visualizing processed data

### How the Code Works 
---

#### **1. `config.py`**

**Defines:**
- App IDs for each bank  
- Number of reviews per bank  
- Retry settings  
- File paths for raw & processed data  

**Purpose:**  
Keeps the entire project configurable without editing individual scripts.

---

#### **2. `scripts/scraper.py`**

**Responsibilities:**
- Loads settings from `config.py`  
- Fetches metadata for each app  
- Scrapes reviews using `google-play-scraper`  
- Saves:  
  - `data/raw/reviews_raw.csv`  
  - `data/raw/app_info.csv`  

**Key Features:**
- Automatically loops through all apps in `APP_IDS`  
- Uses progress bars (`tqdm`)  
- Handles retries  
- Fully reproducible  

**To run:**
```bash
python scripts/scraper.py
```
or run it inside the notebook

#### **3. `scripts/preprocessing.py`**

**Responsibilities:**
- Loads raw scraped data  
- Removes duplicates  
- Drops empty or invalid reviews  
- Normalizes dates  
- Cleans text  
- Validates rating values  
- Adds new columns  
- Saves:  
  - `data/processed/reviews_processed.csv`  

**Generates a detailed report showing:**
- Data retention rate  
- Number of removed rows  
- Rating distribution  
- Review length statistics  
- Reviews per bank  

**To run:**
```bash
python scripts/preprocessing.py
```


### ğŸ“ Project Structure  

```bash
Customer-Experience-Analytics/
â”‚
â”œâ”€â”€ .vscode/
â”‚   â””â”€â”€ settings.json
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ Ci.yml
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â”œâ”€â”€ reviews_raw.csv
â”‚ â”‚ â””â”€â”€ app_info.csv
â”‚ â””â”€â”€ processed/
â”‚ â””â”€â”€ reviews_processed.csv
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ scraper.py
â”‚ â”œâ”€â”€ preprocessing.py
â”‚ â”œâ”€â”€ __init__.py
â”‚ â””â”€â”€ README.md
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ preprocessing_EDA.ipynb
â”‚
â”œâ”€â”€ .env
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ config.py
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

